# CSV Based Logstash configuration template sample. 

input {
  tcp {
         port => "${TCP_PORT:5714}"
  }
  file {
        path => ["/tmp/{}/logs/*.log"]
        type => "plab_log"
        #codec => multiline {
          #pattern => "^\w+[-]+"
          #negate => true
          #what => "previous"
        #}
        start_position => "beginning"
        sincedb_path => "/dev/null"
  }
}

filter {
  if [type] == "plab_log" {
        mutate {
                gsub => [ "message", "\"", "" ]
        }

        csv {
                columns => ["logtime", "thread" , "level" , "class" , "method", "line" , "data"]
                separator => " | "
                skip_empty_columns => true
        }

        date {
                match => [ "logtime", "[MM-dd-yyyy HH:mm:ss:SSS]" ]
                locale => "en"
                add_tag => [ "plab_event_tstamp" ]
        }

        grok {
                match => { "message" => "(?<mdn>[0-9]{10,11})" }
        }

        #TESTING :  This Grok for message can be removed later
#       grok {
                #patterns_dir => ["./patterns"]

                #match => { "message" => "%{TIMESTAMP_ISO8601:timestamp}\s+\[(?<threadname>[^ \]]+)\s\]\s+%{GREEDYDATA:details}" }
                #match => { "message" => "%{GREEDYDATA:details}" }
                #match => { "message" => "(?<mdn>[0-9A-F]{10,11})" }
                #match => { "message" => "%{SYSLOGBASE}" }
                #match => { "message" => "%{WORD:plab_message}" }
#       }


  } else {
    # drop{}
     mutate {
      add_field => {
        "IsDropped" => "DROPPED"
        }
     }
    }
}
